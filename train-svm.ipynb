{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de1c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukad\\.conda\\envs\\audioexplore\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import SpectrogramDataset\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3818d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram shape: (52890, 32, 96)\n",
      "Labels shape: (52890,)\n",
      "Spectrogram dtype: float32\n"
     ]
    }
   ],
   "source": [
    "spectrograms = np.load('data/training.npy')\n",
    "labels = np.load('data/training_labels.npy')\n",
    "\n",
    "print('Spectrogram shape:', spectrograms.shape)\n",
    "print('Labels shape:', labels.shape)\n",
    "\n",
    "print('Spectrogram dtype:', spectrograms.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60917569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 42312\n",
      "Validation samples: 5289\n",
      "Test samples: 5289\n"
     ]
    }
   ],
   "source": [
    "TRAINING_RATIO = 0.8\n",
    "VALIDATION_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "if TRAINING_RATIO + VALIDATION_RATIO + TEST_RATIO != 1:\n",
    "    raise ValueError('Training, validation, and test ratios must sum to 1.')\n",
    "\n",
    "train_size = int(TRAINING_RATIO * len(spectrograms))\n",
    "val_size = int(VALIDATION_RATIO * len(spectrograms))\n",
    "test_size = len(spectrograms) - train_size - val_size\n",
    "\n",
    "train_spectrograms, val_spectrograms, train_labels, val_labels = train_test_split(spectrograms, labels, test_size=val_size, random_state=42)\n",
    "train_spectrograms, test_spectrograms, train_labels, test_labels = train_test_split(train_spectrograms, train_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "print('Training samples:', train_spectrograms.shape[0])\n",
    "print('Validation samples:', val_spectrograms.shape[0])\n",
    "print('Test samples:', test_spectrograms.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5f2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transforms here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23a38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpectrogramDataset(train_spectrograms, train_labels, transform=transform)\n",
    "val_dataset = SpectrogramDataset(val_spectrograms, val_labels, transform=transforms.ToTensor())\n",
    "test_dataset = SpectrogramDataset(test_spectrograms, test_labels, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c60367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLASSES = ['Other', 'Music', 'Human voice', 'Engine sounds', 'Alarm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9592369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape data_set_train: (42312, 3072)\n",
      "Shape data_set_val: (5289, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "train_classes = []\n",
    "val_classes = []\n",
    "\n",
    "\n",
    "for batch, labels in train_loader:\n",
    "    train_data.append(batch.flatten().numpy())\n",
    "    train_classes.append(labels.item())\n",
    "\n",
    "for batch, labels in val_loader:\n",
    "    val_data.append(batch.flatten().numpy())\n",
    "    val_classes.append(labels.item())\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "val_data = np.array(val_data)\n",
    "val_classes = np.array(val_classes)\n",
    "\n",
    "print(\"Shape data_set_train:\", train_data.shape)\n",
    "print(\"Shape data_set_val:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f4c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "start_train_time = time.time()\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "model.fit(train_data, train_classes)\n",
    "print(\"Model trained\")\n",
    "\n",
    "print(\"Train computation time:\", time.time()-start_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22162e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8241913683085531\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "train_predictions = model.predict(train_data)\n",
    "train_accuracy = accuracy_score(train_classes, train_predictions)\n",
    "print(\"Training Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb21967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7801810865191147\n",
      "Validation Computation Time: 163.78705477714539\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "start_val_time = time.time()\n",
    "\n",
    "validation_predictions = model.predict(val_data)\n",
    "validation_accuracy = accuracy_score(val_classes, validation_predictions)\n",
    "\n",
    "print(\"Validation Accuracy:\", validation_accuracy)\n",
    "print(\"Validation Computation Time:\", time.time()-start_val_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e3929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One prediction computation time: 0.048697710037231445\n"
     ]
    }
   ],
   "source": [
    "# Computation time for predicting once\n",
    "train_data_one_label = []\n",
    "\n",
    "for batch, labels in val_loader:\n",
    "    train_data_one_label.append(batch.flatten().numpy())\n",
    "    break\n",
    "\n",
    "one_predict_time_start = time.time()\n",
    "model.predict(train_data_one_label)\n",
    "one_prediction_time = time.time()-one_predict_time_start\n",
    "print(\"One prediction computation time:\", one_prediction_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb93d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model size: 454216189\n"
     ]
    }
   ],
   "source": [
    "# Model size\n",
    "with open(f'svm_model_{int(100/ratio)}.pickle', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "    file.flush()\n",
    "    file.close()\n",
    "\n",
    "print(\"SVM model size:\", os.path.getsize(f'svm_model_{int(100/ratio)}.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2271c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results_{int(100/ratio)}_percent_of_data_set.txt', 'wb') as file:\n",
    "    file.write(f'Training accuracy {train_accuracy}\\n'.encode())\n",
    "    file.write(f'Validation accuracy {validation_accuracy}\\n'.encode())\n",
    "    file.write(f'MB: {int(os.path.getsize(f\"svm_model_{int(100/ratio)}.pickle\"))/1000000}\\n'.encode())\n",
    "    file.write(f'Computation time seconds for one prediction: {one_prediction_time}\\n'.encode())\n",
    "\n",
    "    file.flush()\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioexplore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
